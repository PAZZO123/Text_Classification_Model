{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c921f1f9-f163-455e-a742-5e714217ea46",
   "metadata": {},
   "source": [
    "# Text Classification Model with Pytorch\n",
    "\n",
    "### 1. Import related Libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce084b4-f5ed-457f-aeb9-dfd07c648b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f270004ed30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import urllib\n",
    "import tarfile\n",
    "\n",
    "\n",
    "#set random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b8dd5-e2fc-4de4-b397-22897d9695c7",
   "metadata": {},
   "source": [
    "### 2. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e386ee8-7aae-4138-a4f3-254f220cc5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_imdb(data_dir):\n",
    "    #create data directory\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "        \n",
    "    #Download Imdb dataset\n",
    "    url=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "    file_path=os.path.join(data_dir,\"aclImdb_v1.tar.gz\")\n",
    "    \n",
    "    #Decompress file\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Downloading IMDB dataset ...\")\n",
    "        urllib.request.urlretrieve(url,file_path)\n",
    "        print(\"Downoload Complete!\")\n",
    "        \n",
    "    if not os.path.exists(os.path.join(data_dir,\"aclImdb\")):\n",
    "        print(\"Extracting the dataset!\")\n",
    "        with tarfile.open(file_path,\"r:gz\") as tar:\n",
    "            tar.extractall(path=data_dir)\n",
    "        print(\"Extraction Complete!\")    \n",
    "        \n",
    " #Download Data\n",
    "data_dir=\"data_dir/imdb\"\n",
    "download_imdb(data_dir)   \n",
    " \n",
    "        \n",
    "    \n",
    "    \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153ae37-1744-40c3-8e54-9ac8e026d801",
   "metadata": {},
   "source": [
    "### 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba76f10-f6cf-4ade-8665-f9d9373270ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_data(data_dir):\n",
    "    reviews=[]\n",
    "    labels=[]\n",
    "    \n",
    "    for label_type in ['pos' ,'neg']:\n",
    "        dir_name=os.path.join(data_dir, 'aclImdb','train',label_type)\n",
    "        for fname in os.listdir(dir_name):\n",
    "            if fname.endswith('.txt'):\n",
    "                with open(os.path.join(dir_name, fname),'r',encoding='utf-8') as f:\n",
    "                    reviews.append(f.read())\n",
    "                labels.append(1 if label_type=='pos' else 0)\n",
    "    return reviews, labels           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42257c07-2c7c-4852-9e11-f28390a3b599",
   "metadata": {},
   "source": [
    "### 4. Preprocess data and build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd92f0bd-165c-4564-b07a-1605dbe7c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess text_\n",
    "def preprocess_text(text):\n",
    "    text=re.sub(r'[^\\w\\s]','',text)\n",
    "    text=text.lower()\n",
    "    return text()\n",
    "\n",
    "#Build Vocabulary\n",
    "def build_vocab(reviews,max_vocab_size=10000):\n",
    "    word_counter=Counter()\n",
    "    for review in reviewers:\n",
    "        word_counter.update(review.split())\n",
    "    vocab={word:i+1 for i,(word,_) in enumerate(word_counter.most_common(max_vocab_size))}\n",
    "    vocab['<PAD>']=0 # addition of padding characters\n",
    "    return vocab\n",
    "# Convert the text into index sequence\n",
    "def text_to_sequence(text,vocab):\n",
    "    return [vocab.get(word,0) for word in text.split()]\n",
    "#Pad the sequences\n",
    "def pad_sequence(seq,max_len):\n",
    "    if len(seq)>=max_len:\n",
    "        return seq[:max_len]\n",
    "    else:\n",
    "        return seq+[0]*(max_len-len(seq))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2523d5-3f12-48bf-aaf9-dd91d6f09fb4",
   "metadata": {},
   "source": [
    "### 5. Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c94e27-a8e6-43b9-b250-ff023a2ebaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IMBDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f083e-b224-44a0-829b-02859805eda3",
   "metadata": {},
   "source": [
    "### 6. Define the TxtCnn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7920390-25fb-4d55-873d-8fb55f8540b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size,embed_dim, num_classes, kernel_sizes=[3,4,5], num_filters=100):\n",
    "        super(TextCNN,self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_dim)\n",
    "        self.convs=nn.ModuleList([\n",
    "            nn.Conv2d(1,num_filters, (k, embed_dim)) for k in kernel_sizes\n",
    "        ])\n",
    "        self.fc=nn.Linear(len(kernel_sizes)*num_filters,num_classes)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.embedding(x)\n",
    "        x=x.unsqueeze(1)\n",
    "        x=[torch.relu(conv(x)).seqqueeze(3) for conv in self.convs]\n",
    "        x=[torch.max_pool1d(i,i.size(2)).squeeze(2) for i in x]\n",
    "        x=torch.cat(x,1)\n",
    "        x=self.dropout(x)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dab14-83e5-4090-990c-4b1c6589c474",
   "metadata": {},
   "source": [
    "### 7. Define the model Training and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7096fa8c-6bc1-490b-9cd4-ba0587d3bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss=0\n",
    "        for batch_x ,batch_y in train_loader:\n",
    "            batch_x,batch_y=batch_x.to(device),batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs=model(batch_x)\n",
    "            loss=criterion(outputs,batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss+=loss_item()\n",
    "            \n",
    "        print(f'Train-Epoch[{epoch+1}/{num_epoch}],Loss:{total_loss/len(train_loader):.4f}')\n",
    "        \n",
    "# Model Test Function\n",
    "def test_model(model,test_loader, device):\n",
    "    model.eval()\n",
    "    correct=0\n",
    "    total=0\n",
    "    with torch.no_grad():\n",
    "        for batch_x , batch_y in test_loader:\n",
    "            batch_x, batch_y=batch_x.to(device), batch_y.to(device)\n",
    "            outputs=model(batch_x)\n",
    "            _,predicted=torch.max(outputs.data,1)\n",
    "            total +=batch_y.size(0)\n",
    "            correct +=(predicted==batch_y).sum().item()\n",
    "            \n",
    "    print(f'Test Accuracy:{100*correct/total:.2f}%')      \n",
    "    \n",
    "#Sentiment Prediction Function\n",
    "def predict_sentiment(text,model, vocab, max_len=200):\n",
    "    text=preprocess_text(text)\n",
    "    sequence=pad_sequence(sequence,max_len)\n",
    "    sequence=torch.tensor(sequence,dtype=torch.long).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output=model(sequence)\n",
    "        _,predicted=torch.max(output,1)\n",
    "    return \"pos\" if predicted.item()==1 else \"neg\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8dbbd5-47bd-418c-a668-eb399556c0f4",
   "metadata": {},
   "source": [
    "### 8. Train model on the main program , and test the model accuracy using the test set and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12fe76-498a-4815-bc4e-8cf1024ff4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Program\n",
    "if __name__ ==\"__main__\":\n",
    "    # Download and load\n",
    "    data_dir=\"data_dir/imdb\"\n",
    "    download_imdb(data_dir)\n",
    "    reviews, labels=load_imdb_data(data_dir)\n",
    "    \n",
    "    #preprocess data\n",
    "    reviews=[preprocess_text(reviw ) for review in reviews]\n",
    "    vocab=build_vocab(reviews)\n",
    "    squences=[text_to_sequence(review,vocab) for review in reviews]\n",
    "    \n",
    "    #padd the sequence and split the dataset\n",
    "    max_len=200\n",
    "    x=[pad_sequence(seq,max_len) for seq in sequences]\n",
    "    x=torch.tensor(x,dtype=torch.long)\n",
    "    y=torch.tensor(labels,dtype=torch.long)\n",
    "    \n",
    "    x_train, x_test,y_train, y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
